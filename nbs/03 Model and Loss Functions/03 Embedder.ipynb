{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "# default_exp embed\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import FRED\n",
    "from FRED.embed import *\n",
    "if torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Embedder\n",
    "> At the heart of FRED: the flow embedder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRED's embedder is pretty simple. Given a directed graph along with the coordinates that gave rise to the nodes, FRED embeds it into a lower dimensional space with an autoencoder. FRED also draws a vector field on the embedding space, to endow the embedded points with a sense of flow -- recreating the flows over the directed graph from which they came. FRED is rewarded for drawing arrows such that the flows in the embedding space mimic the flows in the ambient space. And, to give the visualization desirable properties, he is given bonus points for drawing flows that are as smooth as possible - and also placing the points in such a way that they resemble the directed diffusion map. The result is an embedding of the points and velocities that \"respects the flow\" by incorporating flow information into the placement of points.\n",
    "\n",
    "This can also be done *without* the coordinates of the nodes -- e.g. when we have an abstract directed graph, unencumbered by physical coordinates. In this case, a GNN serves as the graph embedder that creates embedding coordinates from the input graph. This is implemented as a separate network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold with Flow Embedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from FRED.data_processing import affinity_matrix_from_pointset_to_pointset\n",
    "\n",
    "class ManifoldFlowEmbedder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dimension=2,\n",
    "        embedder_shape=[3, 4, 8, 4, 2],\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        sigma=0.5,\n",
    "        flow_strength=0.5,\n",
    "        num_negative_samples = 20,\n",
    "        smoothness_grid=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        # embedding parameters\n",
    "        self.sigma = sigma\n",
    "        self.flow_strength = flow_strength\n",
    "        self.smoothness_grid = smoothness_grid\n",
    "        self.num_negative_samples = num_negative_samples\n",
    "        # Initialize autoencoder and flow artist\n",
    "        self.embedder, self.decoder = auto_encoder(embedder_shape, device=self.device)\n",
    "        self.flowArtist = flow_artist(dim=self.embedding_dimension, device=self.device)\n",
    "        # training ops\n",
    "        self.KLD = nn.KLDivLoss(reduction=\"batchmean\", log_target=False)\n",
    "        self.MSE = nn.MSELoss()\n",
    "        # self.KLD = homemade_KLD # when running on mac\n",
    "        self.epsilon = 1e-6  # set zeros to eps\n",
    "\n",
    "    def loss(self, data, loss_weights):\n",
    "        # compute autoencoder loss\n",
    "        losses = {}\n",
    "        if \"reconstruction\" in loss_weights and loss_weights[\"reconstruction\"] != 0:\n",
    "            X_reconstructed = self.decoder(self.embedded_points)\n",
    "            losses[\"reconstruction\"] = self.MSE(X_reconstructed, data[\"X\"])\n",
    "\n",
    "        # Compute diffusion map loss\n",
    "        if \"distance regularization\" in loss_weights and loss_weights[\"distance regularization\"] != 0:\n",
    "            diffmap_loss = precomputed_distance_loss(\n",
    "                data[\"precomputed distances\"], self.embedded_points\n",
    "            )\n",
    "            #           diffmap_loss = diffusion_map_loss(self.P_graph_ts[0], self.embedded_points)\n",
    "            losses[\"distance regularization\"] = diffmap_loss\n",
    "        if \"distance regularization v2\" in loss_weights and loss_weights[\"distance regularization v2\"] != 0:\n",
    "            loss = precomputed_distance_lossV2(\n",
    "                embedded_points=self.embedded_points,\n",
    "                near_distances_precomputed=data['distance to neighbors'],\n",
    "                far_distances_precomputed=data['distance to farbors'],\n",
    "                center_point_idxs=data['center point idxs'],\n",
    "                neighbor_idxs=data['neighbor idxs'],\n",
    "                farbor_idxs=data['farbor idxs'],\n",
    "            )\n",
    "            losses[\"distance regularization v2\"] = loss\n",
    "        # Compute flow neighbor loss\n",
    "        if \"flow neighbor loss\" in loss_weights and loss_weights[\"flow neighbor loss\"] != 0:\n",
    "            neighbor_loss = flow_neighbor_loss(\n",
    "                data[\"neighbors\"],\n",
    "                self.embedded_points,\n",
    "                self.embedded_flows,\n",
    "            )\n",
    "            losses[\"flow neighbor loss\"] = neighbor_loss\n",
    "            \n",
    "        # Computes negative sampling loss\n",
    "        if \"contrastive flow loss\" in loss_weights and loss_weights[\"contrastive flow loss\"] != 0:\n",
    "            # sample random points from the realm outside of the flow neighbors\n",
    "            row = torch.zeros(self.num_negative_samples).long()\n",
    "            negative_sample_idxs = torch.randint(data[\"num flow neighbors\"],len(self.embedded_points),(1,self.num_negative_samples))[0]\n",
    "            not_neighbors = torch.vstack([row, negative_sample_idxs])\n",
    "            # pass these into the contrastive flow loss\n",
    "            loss = contrastive_flow_loss(\n",
    "                not_neighbors,\n",
    "                self.embedded_points,\n",
    "                self.embedded_flows\n",
    "            )\n",
    "            losses[\"contrastive flow loss\"] = loss\n",
    "\n",
    "        # Compute smoothness regularization\n",
    "        if \"smoothness\" in loss_weights and loss_weights[\"smoothness\"] != 0:\n",
    "            smoothness_loss = smoothness_of_vector_field(\n",
    "                self.embedded_points,\n",
    "                self.flowArtist,\n",
    "                device=self.device,\n",
    "                grid_width=20,\n",
    "                use_grid=self.smoothness_grid,\n",
    "            )\n",
    "            losses[\"smoothness\"] = smoothness_loss\n",
    "\n",
    "        if \"kld\" in loss_weights and loss_weights[\"kld\"] != 0:\n",
    "            A = affinity_matrix_from_pointset_to_pointset(self.embedded_points, self.embedded_points, self.embedded_flows, sigma=0.5, flow_strength=1)\n",
    "            P = torch.nn.functional.normalize(A, p=1, dim=1)\n",
    "            losses['kld'] = kl_divergence_loss(P, data[\"P\"])\n",
    "\n",
    "        if \"contrastive loss v2\" in loss_weights and loss_weights[\"contrastive loss v2\"] != 0:\n",
    "            losses['contrastive loss v2'] = contrastive_flow_loss_V2(self.embedded_points, self.embedded_flows, center_point_idxs = data[\"center point idxs\"], neighbor_idxs = data[\"neighbor idxs\"])\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def forward(self, data, loss_weights):\n",
    "        self.embedded_points = self.embedder(data[\"X\"])\n",
    "        self.embedded_flows = self.flowArtist(self.embedded_points)\n",
    "        losses = self.loss(data, loss_weights)\n",
    "        return losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowartist",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
