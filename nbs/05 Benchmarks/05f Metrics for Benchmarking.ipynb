{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Using device mps\n"
    }
   ],
   "source": "# default_exp metrics\nfrom nbdev.showdoc import *\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport FRED\nif torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\nelse:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device\", device)\n%load_ext autoreload\n%autoreload 2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Flow Neighbor Metric\nVerifies that the arrows in embedded space point towards the same points they do in ambient space. This is a wrapper around our flow neighbor loss, to ensure compatibility with other embedding techniques.\n\nThe parameter choices shouldn't impact the outcome too much. Automatic sigma selection works well, and the number of neighbors used is held constant."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# export\nimport torch\nimport numpy as np\nfrom FRED.embed import flow_neighbor_loss\nfrom FRED.data_processing import flashlight_affinity_matrix, diffusion_map_from_affinities, flow_neighbors\nimport torch.nn.functional as F\n\ndef flow_neighbor_metric(X, flows, embedded_points, embedded_velocities):\n    A = flashlight_affinity_matrix(X, flows, sigma = \"automatic\", flow_strength = 5)\n    P_graph = F.normalize(A, p=1, dim=1)\n    neighborhoods = flow_neighbors(num_nodes = len(X), P_graph = P_graph, n_neighbors = 5)\n    row, col = neighborhoods\n    directions = (embedded_points[col] - embedded_points[row])\n    directions = F.normalize(torch.tensor(directions),dim=1)\n    embedded_velocities = torch.tensor(embedded_velocities[row])\n    embedded_velocities = F.normalize(embedded_velocities, dim=1)\n    loss = torch.norm(directions - embedded_velocities)**2\n    # neighbor_score = flow_neighbor_loss(neighborhoods, torch.tensor(embedded_points), torch.tensor(embedded_velocities))\n    return loss"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Silhouette Metric\nCalculates silhouette score, a measure of the separation between classes which ranges from -1 (bad) to 1 (exceptional). Uses both the raw points, and the points with associated flows concatenated. The latter makes very little difference in practice, but might in theory."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# export\nimport sklearn\ndef silhouette_metric(embedded_points, embedded_velocities, labels):\n    points_and_flows = np.concatenate([embedded_points, embedded_velocities], axis=1)\n    silhouette_points = sklearn.metrics.silhouette_score(embedded_points, labels)\n    silhouette_points_and_flows = sklearn.metrics.silhouette_score(points_and_flows, labels)\n    return silhouette_points, silhouette_points_and_flows"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# KNN Classifier Score\nFits a knn classifier to the data, as another measure of the separability of the clusters. This uses the appended arrows by default."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# export\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndef nn_classification_metric(embedded_points, embedded_velocities, labels):\n    points_and_flows = np.concatenate([embedded_points, embedded_velocities], axis=1)\n    X_train, X_test, y_train, y_test = train_test_split(points_and_flows, labels, test_size=0.33, random_state=42)\n    neighClass = KNeighborsClassifier(n_neighbors=3)\n    neighClass.fit(X_train, y_train)\n    knn_classifier_score = neighClass.score(X_test, y_test)\n    return knn_classifier_score"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Monotone Increasing metric\nWith single cell data, there's an easy way to test if the \"flows\" between cells in the embedded space make sense biologically: are the cells always moving forward in time? \n\nPresently, we just test if the timestamps of cells ever decrease (are not monotone increasing) as time progresses. We sum any negative changes from time $t$ to $t+1$ as a measure of the severity of the violation. This is summed over a sample points in the dataset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# export\nfrom FRED.inference import diffusion_flow_integration\nfrom tqdm.notebook import trange, tqdm\ndef monotone_increasing_metric(embedded_points, embedded_velocities, time_labels, num_samples = 100, flow_strength=5):\n    # sample random starting points\n    idxs = torch.randint(len(embedded_points), size=[num_samples])\n    neg_diffs = 0\n    for pointA in tqdm(idxs):\n        flowline = diffusion_flow_integration(torch.tensor(embedded_points), torch.tensor(embedded_velocities), starting_index = pointA, num_steps = 20, flow_strength=flow_strength)\n        flowline = np.array(flowline)\n        # take difference between neighbors in the vector\n        times_at_flowline = time_labels[flowline]\n        neighb_diffs = times_at_flowline[1:] - times_at_flowline[:-1]\n        # print(\"neighb diffs: \",neighb_diffs)\n        # get sums of negative numbers\n        neg_diffs += (np.sum(neighb_diffs) - np.sum(np.abs(neighb_diffs)))/2\n    neg_diffs/num_samples\n    return neg_diffs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Comprehensive Metrics\n\nRun all metrics and save them to a given spreadsheet."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# export\nimport csv\ndef comprehensive_flow_metrics(X, flows, labels, embedded_points, embedded_velocities, time_labels, spreadsheet_name, unid, flow_strength):\n    neighbor_score = flow_neighbor_metric(X, flows, embedded_points,embedded_velocities)\n    silhouette_score, silhouete_score_with_flow = silhouette_metric(embedded_points, embedded_velocities, labels)\n    knn_score = nn_classification_metric(embedded_points, embedded_velocities, labels)\n    monotone_score = monotone_increasing_metric(embedded_points, embedded_velocities, time_labels)\n    print(f\"## SCORES ## \\n silhouette score w/o flows: {silhouette_score}.\\n silhouette score w/ flows:  {silhouete_score_with_flow} \\n kNN Classifier {knn_score} \\n Flow Neighbor Score {neighbor_score} \\n Monotone Increasing Score {monotone_score}\")\n    return silhouette_score, silhouete_score_with_flow, knn_score, neighbor_score, monotone_score\n        "
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
